{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f3f0d8d9475fb4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h1>PHY 2200 - Computational Physics</h1>\n",
    "<h2>Spring 2023</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9acd13e15941811a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Random numbers and what they can do for <i>you</i></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-903aae9ba1fa5c10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The following two lines import the packages ```numpy``` and ```pyplot```, which will be useful for most things we do this semester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-53442b0496c570e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2cf69470829f0a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Estimating $\\pi$</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f2181b5aff957fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How might we use random numbers to estimate $\\pi$? Here's a wacky but ingenious strategy:\n",
    "\n",
    "Consider throwning darts at a square. We know with certainty that they land somewhere in the square. For concreteness, let's take the square side length to be 1 meter (or foot, mile, furlong, whatever).\n",
    "\n",
    "<img src=\"circle.png\" width=\"300\">\n",
    "\n",
    "Now consider a circular arc inscribed into the square, as shown above. Two facts to note: the square's area is 1, and the circular wedge (being a quarter of a circle) has area $\\frac{1}{4} \\pi r^{2} = \\frac{\\pi}{4}$. But why does that matter?\n",
    "\n",
    "We know that each dart will hit <i>somewhere</i> in the square. It's assumed that every point is equally likely---that's the essence of randomness. Then after many, many darts land, the square is uniformly <i>filled</i> with darts. Suppose $N_{c}$ land within the circular arc and a total of $N$ darts landed on the square. Given the uniformity, we can say that\n",
    "\n",
    "$$\\lim_{N\\rightarrow\\infty} \\frac{N_{c}}{N} = \\frac{A_{c}}{A} = \\frac{\\pi}{4},$$\n",
    "\n",
    "where $A_{c} = \\frac{1}{4}\\pi r^{2}$ is the area of the quarter circle and $A = r^{2}$ is the area of the square. In numerical analysis, there is no such thing as taking a limit to infinity. The <i>key</i> is to do something enough times that we <i>saturate</i> the limit (i.e., \"get close enough\") in some controlable manner. Let's see what happens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b613f95aed7249a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How do we perform this experiment numerically? Somehow, we need to simulate darts randomly landing somewhere within our square. Each dart location is given by two-dimensional coordinates, $(x,y)$. We also know that $0\\leq x \\leq 1$ and $0\\leq y \\leq 1$. As it turns out, there's a built-in <b>random number generator</b> in ```numpy```. We'll return to just <i>what</i> this means shortly, but for now you can think of this as a magic trick for generating a \"random\" number between 0 and 1. Here's what you type to get such a \"random\" number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.817612151117982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-51a80d99c5f2306f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Try re-running that command several times, and observe what happens. The human mind is particularly bad at estimating randomness, so it might behave surprisingly. What's more, we can generate <i>arrays</i> of random numbers by adding an <b>argument</b> to the <b>function</b> ```rand()```. By default, this function ```rand()``` returns a single value. If we add an argument, say ```3```, we'll get an array of three \"random\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35253369, 0.86007754, 0.93581716])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8153e512eb4d741e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The array is a useful type of data structure for ```numpy``` functions. Python naturally works with \"lists,\" and there are many similarities (<i>and</i> subtle-but-important differences) between the two structures. It's not my intention to teach you computer programming theory or the intricacies of the Python language. We shall simply look for the quickest way to get useful answers and pick up the technology we need as we need it.\n",
    "\n",
    "Should you want a two-dimensional array of random numbers (e.g., a <i>matrix</i>), you can create that via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80107939, 0.69049322, 0.26006678],\n",
       "       [0.81157548, 0.82965999, 0.84950622]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c10ab485cfe72e6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that the $2\\times 3$ array (```(2,3)```) gives two rows and three colummns. Just for fun, we can also create arrays of <b>zeros</b>. Why? Later, these will be useful for initializing arrays that will be used to store values as we compute them. One rare example of good programming practice that I will actually harp on in this course is that it's a good idea to initialize the structure that stores your ten thousand values <i>before</i> you calculate them if you're going to try to compute ten thousand values (of something). A one-dimensional example of this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31704fb0303d6dd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And fun quirk: say you want to compute a $5\\times 6$ array of zeros. The command ```np.zeros(5,6)``` seems really sensible, doesn't it? Try it. You'll get an error. The correct syntax is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((5,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-17a30176b73593fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Did you try it the other way? Do that. You <b>will</b> run into syntax errors in this class (and beyond). It's part of the process, whether you know the language well or not. Google (or sometimes just [StackOverflow](https://stackoverflow.com/)) is going to be your friend. But the lesson for this class is that: <b>you don't need to know the right syntax; you need to give yourself permission to look up things as you need them.</b> The goal is for you to think about <i>how</i> to solve the problem-how to think computationally. The rest can be looked up as you need it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63e7a520b456f7d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To the matter at hand: we need to create a large number (say $N$) of random points $(x,y)$ inside of our square. Then we need to figure out how many (say $N_{c}$) of these points lie within the circular part. Since we need coordinate pairs, let's initialize $x$ and $y$ as random sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0b38f5e344c9de27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now how to test? We can look at each point and determine whether or not its distance from the origin, $d = \\sqrt{x^{2}+y^{2}}$ is less than the radius (here $r=1$). So we now need to get the computer to (a) <b>loop</b> over all points and (b) perform a logical test.\n",
    "\n",
    "For (a), there is a device known as a <b>for loop</b>, which will repeat a given task <i>for</i> some condition(s). Given each entry, we can test using an <b>if statement</b> which performs a particular operation <i>if</i> a particualr condition is met. Let's have a look at the whole process and break it down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nc = 0 #initialize number of points inside the circle to zero\n",
    "\n",
    "#to count, we'll loop over all values (x[i],y[i]) with i starting at 0 and running over all 20 values\n",
    "for i in range(0,N):\n",
    "    #if x^2 + y^2 < 1, the point is inside the circle; \n",
    "    if (x[i]**2 + y[i]**2 <= 1.0):\n",
    "        Nc = Nc + 1  #if inside the circle, add 1 to the running count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48292855f51ca8d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You'll notice numerous <i>comments</i> within that cell. Commenting your programs is a very healthy practice in which you send a message to others (and often, your future self) which explains what each line does. Sometimes we invent rather ingenious solutions to problems after a great deal of trial and error. Often, these solutions only make sense after living in the weeds of the problem for a while. You might be surprised how baffling a program you wrote can look after a few months of not thinking about the inner workings. \n",
    "\n",
    "All that to say, this is a public service announcement: <b>comment your code</b>.\n",
    "\n",
    "Let's take a look at what happened. We can plot the points along with the semicircular boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5y/f05xx2_d48d4jk28488my0980000gn/T/ipykernel_1559/67762150.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0myc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'k-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "xc = np.linspace(0,1,100)\n",
    "yc = np.sqrt(1.0-xc**2)\n",
    "\n",
    "plt.plot(x,y,'b.')\n",
    "plt.plot(xc,yc,'k-')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9952fed678b03a3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now what we <i>should</i> have is the total number of out darts (out of $N$) that landed inside the circle. Our agument is that the ratio $N_{c}/N$ should approach the ratio of areas, $\\frac{\\pi}{4}$ as $N$ \"gets really big.\" So our estimate for $\\pi$ is then $\\pi \\approx 4N_{C}/N$, or:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.0*Nc/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e9f8e0d4facd174d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That's close to the actual value of 3.141952... right? Take a moment to try smaller or larger values of $N$ to get a sense for how this affects the estimate. Then congratulate yourself for performing your first <b>Monte Carlo simulation</b>. You would be surprised how much of modern computational physics uses simple devices like this to do real calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0aba063386b6ebc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h2>Evaluating the estimate</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-710f627423da0318",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "At this point, you should have discovered that this silly dart throwing simulation appears to be a not-unreasonable way to estimate $\\pi$, one of the fundamental mathematical constants. But we already have a $\\pi$ button on our calculator. Even ```numpy``` knows $\\pi$ to many decimal places:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3bac5bd741f1994",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "* Question - Did we need the ```print()``` function right there? (find out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-754ff293ac7a495c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Depending on how large you let $N$ become, you might get 1-2 decimal places of accuracy after the 3 before Python gets really bogged down looping over a very large number of dart tosses. In this case, it's <i>easy</i> to assess the accuracy of our estimate <i>because we know the exact answer</i>. We can do any number of comparisons, but let's just look at the <b>relative error</b>. In words, you look at the difference between the estimate and the exact value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0944073464102071\n"
     ]
    }
   ],
   "source": [
    "piapprox = 4.0*Nc/N\n",
    "\n",
    "error = np.pi - piapprox\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c5a5d0b070bf5c2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Absolute error, like this, isn't a great way to convey how close an estimate is. An error of less than 0.06 sounds small because the exact answer is roughly 3. But if we had an error of 0.06 and the exact answer was itself 0.06, this would be a much less precise estimate. So let's convert this to a fraction of the exact answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03005079169074672\n"
     ]
    }
   ],
   "source": [
    "relerror = error/np.pi\n",
    "print(relerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a44b6519fd3d8644",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So that tells us that our estimate is only about 1.8% away from the true value. This sounds alright, but I present two important questions related to this:\n",
    "\n",
    "1. What happens if you repeat the calculation? It's based on random numbers, so your estimate will change somewhat each time you calculate it (yes, even for fixed $N$).\n",
    "\n",
    "2. Calculating $\\pi$ is instructive. But we know the answer already. This method is actually more useful when we don't know the answer (or have any other way to calculate it easily). So how do we assess \"how good our estimate is\" when we don't know the exact answer?\n",
    "\n",
    "These questions motivate the difference between <b>accuracy</b> and <b>precision</b>:\n",
    "<center>\n",
    "<img src=\"precision.png\" width=\"300\">\n",
    "(image: <a href=https://wp.stolaf.edu/it/gis-precision-accuracy/>https://wp.stolaf.edu/it/gis-precision-accuracy/</a>)\n",
    "</center>\n",
    "\n",
    "Comparing to the known value is a test for accuracy of the estimate. But if we repeat the calculation and get wildly varying estimates, we would say that our estimation scheme is not precise. \n",
    "\n",
    "Mathematically, the Monte Carlo method is known to <i>converge</i> to the correct answer. That means, in the limit $N\\rightarrow \\infty$, someone can prove to you that the estimation approaches the exact answer. In computational work, our $N$ is always finite, so we will now turn our attention to how we can assess precision at some finite $N$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-74ee67320002a2f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The basic idea of estimating precision is to repeat the calculation an examine how the result varies due to statistical fluctuations. Note the nested thinking: we loop over a loop a large number of random values. It will help to define a function to perform the basic Monte Carlo estimation so that we can simply loop over this function. Why write something many times when you can just write it (carefully) once?\n",
    "\n",
    "To this end, let's define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e753e51e28c49a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def montecarloPi(N):\n",
    "    \n",
    "    Nc = 0\n",
    "    \n",
    "    x = np.random.rand(N)\n",
    "    y = np.random.rand(N)\n",
    "    \n",
    "    rsq = x**2 + y**2\n",
    "    \n",
    "    for i in range(0,N):\n",
    "        if (rsq[i]<=1.0):\n",
    "            Nc = Nc + 1\n",
    "            \n",
    "    estimate = 4.0*Nc/N\n",
    "    return estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-222a22f2e9bbfaf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can call this thing to perform a Monte Carlo estimate of $\\pi$ for any value of $N$. The only major difference from what we did above is that here we use array operations (```x*x+y*y```) to precompute the values of $r^{2}$ at the beginning rather than performing the calculation for each point. This is a simple example of <b>vectorization</b> which can get around certain operations being slow. Below, we'll see that you can actually use <b>logical indexing</b> to get around the loop entirely (and likely speed up the calculation!).\n",
    "\n",
    "So let's do the following with our function. Define an array of $N_{samples}$ zeros. In each of these slots, we will place a Monte Carlo estimate for $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.156 3.112 3.204 3.204 3.088 3.136 3.16  3.004 3.128 3.088 3.128 3.136\n",
      " 3.02  3.06  3.224 3.164 3.212 3.108 3.1   3.16  3.168 3.076 3.16  3.124\n",
      " 3.184 3.104 3.1   3.116 3.096 3.076 3.104 3.092 3.14  3.108 3.088 3.136\n",
      " 3.056 3.164 3.18  3.292 3.116 3.076 3.184 3.108 3.156 3.068 3.044 3.16\n",
      " 3.152 3.048 3.128 3.124 3.108 3.116 3.124 3.192 3.124 3.04  3.156 3.148\n",
      " 3.284 3.188 3.208 3.096 3.188 3.188 3.1   3.124 3.108 3.072 3.148 3.236\n",
      " 3.148 3.192 3.124 3.128 3.152 3.156 3.132 3.144 3.148 3.26  3.124 3.076\n",
      " 3.088 3.152 3.132 3.22  3.06  3.116 3.14  3.164 3.184 3.176 3.12  3.168\n",
      " 3.152 3.224 3.112 3.232]\n"
     ]
    }
   ],
   "source": [
    "Nsamples = 100\n",
    "piSamples = np.zeros(Nsamples)\n",
    "\n",
    "for i in range(0,Nsamples):\n",
    "    piSamples[i] = montecarloPi(1000)\n",
    "    \n",
    "print(piSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dd2f05dd7f1257a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now you or I can easily look at this list of values and say to ourselves, \"Hm. They look pretty close to 3.14.\" We would like to be more precise. A simple measure of statistical variation is the <b>variance</b> $\\sigma^{2}$, which can be <i>estimated</i> from a sample of $N$ points $x_{i}$ by\n",
    "\n",
    "$$\\sigma^{2} = \\frac{\\displaystyle \\sum_{i=1}^{N}(x_{i}-\\overline{x})^{2}}{N-1}$$\n",
    "\n",
    "Here $\\overline{x}$ is the average value of the $x_{i}$, and this variance is essentially averaging the squared (why?) deviation of the points from the mean. If we take the square root to obtain the <b>standard deviation</b> $\\sigma$, we get a rough estimate for the average distance of each point from the average. That's a decent estimate of how much uncertainty we have in our estimate since it measures the spread of values.\n",
    "\n",
    "Lucky for us, ```numpy``` has this function built in and we can just use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our estimate of pi is 3.13692+/-0.05331222749051104\n"
     ]
    }
   ],
   "source": [
    "piEstimate = np.average(piSamples)\n",
    "piUncert = np.sqrt(np.var(piSamples))\n",
    "\n",
    "print('Our estimate of pi is ' + str(piEstimate) + '+/-' + str(piUncert))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f4e4e085aed6d962",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note the concatenation (joining together) of strings as well as the conversion of floating point values to strings. Also, note that there's another function ```np.std()``` which returns $\\sigma$ directly. You should check to see if it's identical or just close to what we found.\n",
    "\n",
    "What this says is that the estimate for $\\pi$ should be within about $0.047$ of the real value. Indeed, it is! But now we have confidence for our estimate independent of knowing the actual value. \n",
    "\n",
    "Getting $\\pi \\approx 3.15 \\pm 0.05$ is potentially a little underwhelming. Of course, we could crank up the value of $N$, but it turns out there are somewhat diminishing returns (doubling $N$ won't cut the error in half). Let us now examine how the statistical error ($\\sigma$) scales with $N$.\n",
    "\n",
    "Let us abstract our thinking by one additional level and define a function which does what we just did for $N_{samples}$ estimates of $\\pi$, each with $N$ individual darts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7e0466ab0a015f8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def montecarloPiError(N,Nsamples):\n",
    "    piSamples = np.zeros(Nsamples)\n",
    "\n",
    "    for i in range(0,Nsamples):\n",
    "        piSamples[i] = montecarloPi(N)\n",
    "        \n",
    "    return np.std(piSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-944b560b02efd0d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "So this one function, which calls another function inside a loop, should return the single value for the standard deviation of a bunch ($N_{samples}$) of independent Monte Carlo samples for $\\pi$. Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05451486402807956"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montecarloPiError(1000,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce753e3dcec84edb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Roughly what we got last time, right? Good. Now let's try it for a range of $N$ values. Fun tidbit: you can use Greek letters as variable names by typing them out, beginning with a backslash, and hitting ```TAB```. So $\\sigma$ appears from ```\\sigma``` followed by ```TAB```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvals = [10,30,100,300,1000,3000,10000,30000,100000]\n",
    "σ = np.zeros(len(Nvals)) #make an array of zeros of the same size as Nvals\n",
    "\n",
    "for i in range(0,len(Nvals)): #loop over each of the values of N (len() gives the length of a list)\n",
    "    σ[i] = montecarloPiError(Nvals[i],100) #for each N, calculate σ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b100b91b8c402285",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That might have taken a moment or two. For a reasonably small data set, we can always just have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54552727 0.31406723 0.15444093 0.09456671 0.05283724 0.02958239\n",
      " 0.0146916  0.00947661 0.00487038]\n"
     ]
    }
   ],
   "source": [
    "print(σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-29bda2a504543e09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The values get smaller as $N$ increases. Good, that's what the mathematicians say is supposed to happen. It's always nice when theory and experiment (reality) agree. But we can actually look a little closer at <i>how</i> the convergence occurs. One way to do this visually is to make a simple plot of $\\sigma$ vs $N$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Nvals,σ,'b.') #the 'b.' means \"blue dots\" but you could use 'k-' for \"black line\" or any number of variations\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('σ')\n",
    "plt.show()\n",
    "# you can just use this as a template for a basic plot in the future\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b1f615bdce339a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The plot is clearly nonlinear (fancyspeak for \"not a straight line\"), and we would like to have a sense for how it behaves. Why? Because if we know the convergence rate, we can work out how big $N$ has to be to get the appropriate precision. \n",
    "\n",
    "You might have some experience doing \"curve fitting,\" and it turns out ```numpy``` can do that kind of operation also. But when dealing with nonlinear data, it's often helpful to get a sense for what kind of function is appropriate by using <b>logarithmic scales</b>. For example, suppose we have a data set $(x_{n},y_{n})$ that shows <b>power-law</b> behavior:\n",
    "\n",
    "$$y(x) = Ax^{n}$$\n",
    "\n",
    "for some constants $A$, $n$. Take the natural logarithm (or really <i>any</i> logarithm) of both sides to get\n",
    "\n",
    "$$\\ln y = \\ln[Ax^{q}] = \\ln x^{q} + \\ln A = q\\ln x + \\ln A$$\n",
    "\n",
    "In the last steps, I used $\\ln ab = \\ln a + \\ln b$ and $\\ln a^{b} = b\\ln a$. What this means ($\\ln y = q\\ln x + \\ln A$) is that the logarithm of $y$ is a <i>linear</i> function with respect to the logarithm of $x$. Plotting $\\ln y$ vs $\\ln x$ is referred to as a log-log plot, and it's a quick test for power-law behavior. Another type of common trend is $y = Ae^{\\lambda x}$ which can be linearized by plotting $\\ln y$ vs $x$ (semi-log scale). But the power-law behavior turns out to be relevant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.loglog(Nvals,σ,'b.')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('σ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb4cddb80782e53a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That's not a bad straight line! In order words, we expect $\\sigma \\approx A N^{q}$ for some constants $A$ and $q$. We can obtain these values by performing a linear fit on $\\ln \\sigma$ vs $\\ln N$ as follows. The function ```polyfit(x,y,n)``` will actually perfrom a polynomial fit (of degree $n$) to a data set $(x,y)$. So for a straight line ($n = 1$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.polyfit(np.log(Nvals),np.log(σ),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-367c70f7da1e956e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The array ```p``` will be a set of coefficients for the polynomial fit, $y = p_{n}x^{n} + \\cdots + p_{0}$ so we should get two values corresponding to $\\ln \\sigma = p_{1}\\ln N + p_{0}$, or\n",
    "\n",
    "$$\\sigma = e^{p_{1}\\ln N + p_{0}} = e^{p_{0}} N^{p_{1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51026749  0.55111694]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8b3aba3a2449c19f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That is $\\sigma \\sim N^{-0.49}$. Mathematicians tell us that $\\sigma$ should decay as $\\frac{1}{\\sqrt{N}} = N^{-1/2}$, so we're actually pretty close. Letting $N = 10^{5}$ stand in for infinity is pretty crude, so it's expected that we wouldn't quite saturate the limit for this convergence rate.\n",
    "\n",
    "But the <i>meaning</i> of this is the following: If $\\sigma$ behaves like $N^{-1/2}$, we have to use <b>four</b> times as many samples to get half the error. To reduce the error by a factor of 10, we'd need to increase the samples by a factor of 100. It's a costly method!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercises</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b09ce0b2c807aaad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>1. The Monty Hall Problem</h3>\n",
    "\n",
    "[Monty Hall](https://en.wikipedia.org/wiki/Monty_Hall_problem) (no relation to Monte Carlo) was a TV host in the 1960s-70s who gave contenstants the following challenge:\n",
    "\n",
    "There are three doors. Behind one door is a brand new car. Behind each of the other two doors is a goat (presumably undesirable). A contestant would select one door (let's say Door 1). Before revealing what was behind the door, Monty Hall would open one of the two doors not chosen (let's say Door 2), revealing a goat. At this point the car has to be behind either Door 1 or Door 3.\n",
    "\n",
    "The real kicker comes here: Monty would give the guest the option of switching. The question is: does it make more sense to stick with the original choice or to switch now that more information has been revealed? This can be quite counterintuitive, so we're going to run a simulation to determine the optimal strategy.\n",
    "\n",
    "Also, a fun video on how to think about this problem: [Numberphile](https://www.youtube.com/watch?v=7u6kFlWZOWg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f748dbbc4d577017",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def doorNumber2(doorCar,doorContestant):\n",
    "    ### BEGIN SOLUTION\n",
    "    c = 0\n",
    "    while (c==0):\n",
    "        c = 1\n",
    "        doorMonty = np.random.randint(3)\n",
    "        if (doorMonty==doorContestant):\n",
    "            c = 0\n",
    "        if (doorMonty==doorCar):\n",
    "            c = 0\n",
    "            \n",
    "    return 3 - doorMonty - doorContestant\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c63bd41f5a372189",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''case 1'''\n",
    "assert np.isclose(1,doorNumber2(1,2))\n",
    "### BEGIN HIDDEN TESTS\n",
    "'''case 4'''\n",
    "assert np.isclose(2,doorNumber2(2,0))\n",
    "'''case 5'''\n",
    "assert np.isclose(0,doorNumber2(0,2))\n",
    "'''case 6'''\n",
    "assert np.isclose(1,doorNumber2(1,0))\n",
    "'''case 7'''\n",
    "assert np.isclose(0,doorNumber2(0,1))\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staying wins 0.33\n",
      "Switching wins 0.67\n"
     ]
    }
   ],
   "source": [
    "N = 10000\n",
    "\n",
    "Nswitch = 0 \n",
    "Nstay = 0\n",
    "\n",
    "for i in range(0,N):\n",
    "    #determine which door has car\n",
    "    doorCar = np.random.randint(3)\n",
    "    \n",
    "    #contestant selects door\n",
    "    doorContestant = np.random.randint(3)\n",
    "    \n",
    "    doorRemains = doorNumber2(doorCar,doorContestant)\n",
    "    \n",
    "    if (doorContestant==doorCar):\n",
    "        Nstay = Nstay + 1\n",
    "        \n",
    "    if (doorRemains==doorCar):\n",
    "        Nswitch = Nswitch + 1\n",
    "        \n",
    "print('Staying wins ' + str(Nstay/N))\n",
    "print('Switching wins ' + str(Nswitch/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Semi-log plots and exponential fitting</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8a46aca8287f511f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider the following data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5a015caaea4f1404",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = [0,1,2,3,4,5,6,7,8,9]\n",
    "y = [1.00,0.354,0.128,0.0469,0.0172,0.00630,0.00231,0.000850,0.000312,0.000148]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6d1471366a99b322",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Make a plot of the data using semilog axes (determine whether ```semilogx()``` or ```semilogy()``` is what you want). Based on the plots, write a function that uses ```polyfit``` to determine the constants $\\lambda$ and $A$ in \n",
    "\n",
    "$$y = Ae^{\\lambda t}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Plots:\n",
    "\n",
    "## Make plots here:\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7a32ff8949a86c54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# linear fit to ln(y) vs x *OR* ln(y) vs ln(x)\n",
    "\n",
    "def λfit(x,y):\n",
    "    ### BEGIN SOLUTION\n",
    "    p = np.polyfit(x,np.log(y),1)\n",
    "    \n",
    "    λ = p[0]\n",
    "    A = np.exp(p[1])\n",
    "    \n",
    "    return λ, A\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-19fc9d7f659699a8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "'''case 1'''\n",
    "x = np.linspace(0,2,100)\n",
    "y = np.exp(-x)\n",
    "a,b = λfit(x,y)\n",
    "assert np.isclose(-1,a)\n",
    "'''case 2'''\n",
    "x = np.linspace(2,20,100)\n",
    "y = np.exp(3*x)\n",
    "a,b = λfit(x,y)\n",
    "assert np.isclose(3,a)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ,A = λfit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-96ace656197c7263",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>3. Testing randomness</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a484d97710361237",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When you call ```np.random.rand()```, do you <i>really</i> get a truly random number? It turns out you don't. The proper term is <b>pseudorandom</b> numbers. But for practical purposes, they are often \"close enough.\"\n",
    "\n",
    "So what properties would a truly random set of numbers have? We used the main idea already in doing the Monte Carlo simulation of $\\pi$: they are of uniform probability density. So just to simplify, let's take a sequence of random numbers $0\\leq x_{i} \\leq 1$. First, since the probability distribution is uniform, we expect the number of values smaller than $\\frac{1}{2}$ to be equal to the number of values larger than $\\frac{1}{2}$ (up to statistical fluctuations). More precisely, the average should be pretty close to 0.5.\n",
    "\n",
    "Check that this is (approximately) true for a large list of random values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5024943608334604\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(10000)\n",
    "\n",
    "print(np.average(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-18c24142dbe9fa4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "More generally, the higher <b>moments</b> should satisfy nice properties as well. To get a sense for why this is, try sorting the numbers (```np.sort``` is your friend) and make a simple plot (```plt.plot(np.sort(x),'k.')```). What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sort(x),'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-65abec93651061ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "It should look essentially like a straight line. That's not surprising if this really is approximating a uniform distribution. In the limit $N\\rightarrow \\infty$, we fill in <i>all</i> the real values on $[0,1]$. But this means we can compare the properties of this sample to those of the continuous line $y = x$ (which samples <i>every</i> value in this range). One thing I know is that the average $\\overline{y}$ is\n",
    "\n",
    "$$\\overline{y} = \\frac{\\displaystyle \\int_{0}^{1}xdx}{\\displaystyle \\int_{0}^{1}dx} = \\frac{1}{2}.$$\n",
    "\n",
    "That's what we've already seen. But the higher moments behave according to \n",
    "\n",
    "$$\\overline{y^{2}} = \\int_{0}^{1}x^{n}dx = \\frac{1}{n+1}$$\n",
    "\n",
    "In terms of the discrete, randomly sample values that means (for truly random $x_{i}$) we should get\n",
    "\n",
    "$$\\frac{1}{N}\\sum_{i=1}^{N}x_{i}^{n} \\Longrightarrow \\frac{1}{n+1}$$\n",
    "\n",
    "Write a function ```randomMoment(n)``` which computes the $n^{\\mbox{th}}$ moment of the sample as described here and also returns the relative error (with respect to the predicted value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6687331abc889e14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def randomMoment(x,n):\n",
    "    ### BEGIN SOLUTION\n",
    "    N = len(x)\n",
    "    moment = sum(x**n)/N\n",
    "    predicted = 1/(n+1)\n",
    "    relerror = abs(moment-predicted)/predicted\n",
    "    \n",
    "    return moment, relerror\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-93068fecabd4d6ea",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''case 1'''\n",
    "x = np.random.rand(1000)\n",
    "avg, err = randomMoment(x,1)\n",
    "assert np.isclose(0.5,avg,atol=.05)\n",
    "### BEGIN HIDDEN TESTS\n",
    "'''case 2'''\n",
    "y = np.exp(np.linspace(0,1,100))\n",
    "avg, err = randomMoment(y,3)\n",
    "assert np.isclose(6.4041368,avg,atol=.01)\n",
    "'''case 3'''\n",
    "y = np.cos(np.linspace(0,1,100))\n",
    "avg, err = randomMoment(y,4)\n",
    "assert np.isclose(0.5783091727979058,avg,atol=.01)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.334906282766704, 0.0047188483001119885)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomMoment(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.09241432425383224, 0.0165575667921546)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomMoment(x,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-508cc0defe8575da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>4. Introduction to Monte Carlo integration</h3>\n",
    "\n",
    "The previous suggests that the Monte Carlo approach is also quite useful for evaluating integrals (you know, your favorite task from calculus) numerically. The basic idea is illustrated by considering some function of a single variable, say $f(x)$. We'll see later that this will also work for multi-dimensional integrals. In fact it's far more useful for multi-dimensional integrals.\n",
    "\n",
    "Let's say we wish to compute \n",
    "\n",
    "$$\\int_{a}^{b}f(x)dx$$\n",
    "\n",
    "Then if we can randomly sample points on $[a,b]$, we can approximate the integral as\n",
    "\n",
    "$$\\int_{a}^{b}f(x)dx = \\lim_{N\\rightarrow \\infty}\\sum_{i=1}^{\\infty}f(x_{i})$$\n",
    "\n",
    "Indeed, this is essentially how we worked out the ratio of areas when estimating $\\pi$. This Monte Carlo integration is closely related to the <b>mean value theorem</b> in calculus. \n",
    "\n",
    "Write a function which calculates <i>any</i> function of $x$ you like. It could be $y = x^{2}$, $\\cos x$, $\\ln x$, whatever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(x):\n",
    "    f = x**2\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5218e086d7eaabd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have a function to integrate, write a short Python function to perform the Monte Carlo integration of ```f(x)``` over the range $a\\leq x \\leq b$. The first step is to construct a random sampling of points in this range. I would recommend taking a random sample between 0 and 1 (```random.rand()```) and the scaling it up by a multiplicative factor $(b-a)$ to get the right range. This is now a sample ranging from $0$ to $b-a$. If you add $a$ to each value, it represents a random sample on the correct range.\n",
    "\n",
    "If you want, you can test your function with some known integral like\n",
    "\n",
    "$$\\int_{0}^{1}x^{2}dx = \\frac{1}{3}$$\n",
    "\n",
    "(or <i>any</i> other known integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-001a4d3b4d9f2d72",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def mcint(f,a,b,N):\n",
    "    ### BEGIN SOLUTION\n",
    "    x = a + (b-a)*np.random.rand(N)\n",
    "    integralf = (1/N)*sum(f(x))\n",
    "    return integralf\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3c9d16bc4cd8a1e0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''case 1'''\n",
    "def f1(x):\n",
    "    return x**2\n",
    "\n",
    "assert np.isclose(0.33,mcint(f1,0,1,10000),atol=.05)\n",
    "### BEGIN HIDDEN TESTS\n",
    "'''case 2'''\n",
    "def f1(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "assert np.isclose(0.84,mcint(f1,0,1,10000),atol=.05)\n",
    "'''case 3'''\n",
    "def f1(x):\n",
    "    return np.exp(-x**2)\n",
    "\n",
    "assert np.isclose(0.74,mcint(f1,0,1,10000),atol=.05)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4388503d0e1a26ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<h3>5. Logical indexing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7931a9d0cb3e553",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One of the pitfalls of Python is that it's <i>very</i> slow with loops. You might not notice this for simple calculations, but it becomes quite evident when we scale up to larger calculations. Just keep adding zeros to $N$ in a simple Monte Carlo calculation until starts taking a realy long time. \n",
    "\n",
    "One way to ameliorate this slowness is to avoid using loops. How? Some operations can be <b>vectorized</b> to make use of speedy algorithms, essentially performing the loopable operation in what looks like a single step. For example, if we want to compute $r^{2} = x^{2} + y^{2}$ for each $(x,y)$ in a set, we can write\n",
    "\n",
    "```rsq = x**2 + y**2```\n",
    "\n",
    "However, we still looped over all the values of $r^{2}$ and tested whether each was greater than unity. We can actually do that <i>without</i> an explicit loop using <b>logical indexing</b>, which uses a logical statement in the index to automatically pick off all values satisfying a certain condition. For example, consider the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([3,1,6,9,2,10,4,8,5,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-25be8d0e10eb0cb5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Suppose we want only the values larger than 5. We could loop over the values and test each one <i>or</i> we can use the following trick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  9, 10,  8,  7])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[z>5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d84f66a398d039f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When the index of the array element is replaced by a logical test (\"is the entry larger than 5\"), ```numpy``` will return only the entries which pass the test while preserving the original ordering. Maybe we don't care about the values, but only <i>how many</i> values pass a given test. In this case, we can use the ```len()``` function to simply extract the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(z[z>5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d6313848e4003c9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Use this basic type of logical indexing to rewrite the function ```montecarloPi()``` without using a loop. Does this new version show any obvious change to performance? You might need to crank up $N > 10^{6}$ to see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-284b13d74af05c13",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def montecarloPiLogical(N):\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    x = np.random.rand(N)\n",
    "    y = np.random.rand(N)\n",
    "    \n",
    "    rsq = x**2 + y**2\n",
    "    \n",
    "    Nc = len(rsq[rsq<=1])\n",
    "            \n",
    "    estimate = 4.0*Nc/N\n",
    "    return estimate\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1417774"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montecarloPi(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1413756"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montecarloPiLogical(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7d3e6463c963e93e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "'''case 2'''\n",
    "assert np.isclose(3.14,montecarloPiLogical(10000000),atol=.01)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
